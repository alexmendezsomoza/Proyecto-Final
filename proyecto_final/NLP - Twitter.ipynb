{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38bebac",
   "metadata": {},
   "source": [
    "# Modelo NLP - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f40ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "#!pip3 install scikit-learn\n",
    "#!pip3 install -U spacy\n",
    "#!python3 -m spacy download es\n",
    "#!python3 -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebfb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980d9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae8b0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b198602",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ed9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hay un gato en la casa. Hay una granja en la nevera. Esta es una tercera frase'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0bea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90a03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay\n",
      "un\n",
      "gato\n",
      "en\n",
      "la\n",
      "casa\n",
      ".\n",
      "Hay\n",
      "una\n",
      "granja\n",
      "en\n",
      "la\n",
      "nevera\n",
      ".\n",
      "Esta\n",
      "es\n",
      "una\n",
      "tercera\n",
      "frase\n"
     ]
    }
   ],
   "source": [
    "for token in doc: #ver los tokens/elemento de texto que encuentra la libreria\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a5e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orac = nlp.create_pipe('sentencizer') # 1ª Tuberia/Fase procesamiento. Esto separa la oracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0454801",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(orac, before='parser') # Se añade al pipe e identifica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab1d4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = doc = nlp (text) #Volvemos a pasar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44bdf777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un gato en la casa.\n",
      "Hay una granja en la nevera.\n",
      "Esta es una tercera frase\n"
     ]
    }
   ],
   "source": [
    "for orac in doc.sents: #Ahora, separa en frase\n",
    "    print(orac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b27bf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mismo', 'igual', 'nuestra', 'hemos', 'mios', 'tu', 'usted', 'sí', 'otro', 'podeis', 'adelante', 'allí', 'cada', 'hablan', 'empleo', 'intenta', 'toda', 'despues', 'detrás', 'tal', 'contigo', 'mío', 'paìs', 'cinco', 'podría', 'ampleamos', 'poder', 'alrededor', 'solas', 'uso', 'fuimos', 'he', 'estado', 'hago', 'vamos', 'ello', 'deben', 'general', 'hacia', 'existe', 'hubo', 'nuevas', 'pero', 'parece', 'varias', 'dia', 'conocer', 'esa', 'mencionó', 'días', 'aquel', 'embargo', 'intento', 'intentais', 'quienes', 'anterior', 'la', 'unos', 'casi', 'después', 'aquél', 'trabajar', 'alguna', 'siendo', 'estamos', 'dado', 'final', 'verdadero', 'lo', 'cuándo', 'cual', 'consigues', 'ella', 'nosotros', 'podria', 'aun', 'nos', 'cuántas', 'tercera', 'todo', 'arribaabajo', 'de', 'nadie', 'otras', 'pueda', 'sois', 'dicho', 'trabajan', 'expresó', 'teneis', 'aquí', 'momento', 'mayor', 'nuestros', 'quién', 'donde', 'tuya', 'ciertas', 'ex', 'fui', 'gueno', 'trabajo', 'mucho', 'un', 'mias', 'estados', 'tarde', 'yo', 'mismas', 'que', 'hoy', 'ninguna', 'trata', 'soy', 'solo', 'ir', 'quizas', 'próximos', 'realizado', 'aquellas', 'cuanto', 'les', 'del', 'última', 'supuesto', 'os', 'consigue', 'muchos', 'vosotras', 'podriamos', 'cuenta', 'sé', 'cuantos', 'mucha', 'vais', 'quedó', 'aquéllas', 'dar', 'estoy', 'quiere', 'mejor', 'tambien', 'pronto', 'realizar', 'ante', 'hicieron', 'trabaja', 'siguiente', 'eran', 'sus', 'emplear', 'fueron', 'tampoco', 'ti', 'muy', 'qeu', 'míos', 'suya', 'solos', 'tengo', 'hace', 'tiene', 'tenemos', 'esos', 'buenos', 'cuáles', 'me', 'mal', 'saben', 'cuantas', 'mí', 'poca', 'demás', 'siete', 'aquélla', 'adrede', 'dos', 'atras', 'al', 'éstas', 'serán', 'hizo', 'no', 'tendrán', 'dio', 'mismos', 'propios', 'esto', 'uno', 'verdad', 'próximo', 'algunas', 'ningunos', 'lugar', 'cuánto', 'buen', 'pueden', 'ayer', 'el', 'menudo', 'través', 'ciertos', 'con', 'ese', 'pasado', 'mia', 'considera', 'porque', 'trabajas', 'usas', 'segundo', 'ésos', 'intentan', 'dentro', 'informo', 'haces', 'ningún', 'tres', 'conseguir', 'están', 'día', 'alli', 'propia', 'intentar', 'soyos', 'eso', 'dicen', 'pasada', 'demasiado', 'estar', 'fuera', 'nuevos', 'suyas', 'ésas', 'vosotros', 'medio', 'cómo', 'habia', 'sabeis', 'vaya', 'le', 'usar', 'afirmó', 'principalmente', 'va', 'conmigo', 'hacen', 'debe', 'consiguen', 'respecto', 'aquéllos', 'horas', 'raras', 'hacer', 'sabe', 'trabajais', 'dijo', 'haya', 'temprano', 'además', 'algo', 'haber', 'las', 'buenas', 'todavía', 'partir', 'hasta', 'durante', 'otra', 'encuentra', 'algunos', 'acuerdo', 'buena', 'aqui', 'hacerlo', 'sin', 'cosas', 'han', 'peor', 'así', 'podrían', 'salvo', 'tuvo', 'tener', 'mas', 'emplean', 'dónde', 'tuyas', 'pesar', 'consigo', 'podrian', 'podrá', 'nunca', 'primero', 'intentamos', 'nueva', 'sola', 'cuántos', 'tan', 'se', 'ahí', 'tanto', 'usan', 'ahora', 'tiempo', 'delante', 'misma', 'usa', 'estan', 'detras', 'usais', 'arriba', 'tú', 'solamente', 'en', 'aquellos', 'enfrente', 'suyo', 'pudo', 'su', 'estuvo', 'aquella', 'este', 'últimos', 'modo', 'tus', 'sido', 'quizá', 'podemos', 'saber', 'era', 'cuatro', 'sera', 'total', 'da', 'antaño', 'cerca', 'aproximadamente', 'repente', 'ése', 'actualmente', 'ningunas', 'hecho', 'dice', 'vez', 'quien', 'enseguida', 'mi', 'habla', 'eramos', 'haciendo', 'puedo', 'diferente', 'estaban', 'eras', 'pocas', 'van', 'verdadera', 'parte', 'ha', 'sigue', 'pocos', 'tenido', 'ustedes', 'luego', 'voy', 'sean', 'poner', 'hay', 'estos', 'sólo', 'fin', 'antano', 'ya', 'hacemos', 'también', 'puede', 'asi', 'antes', 'manera', 'quiza', 'estará', 'dan', 'primer', 'te', 'queremos', 'estas', 'explicó', 'somos', 'largo', 'usamos', 'éste', 'señaló', 'indicó', 'será', 'si', 'veces', 'proximo', 'sabemos', 'sobre', 'mía', 'nuestro', 'empleas', 'primera', 'habían', 'conseguimos', 'estais', 'poco', 'vuestro', 'despacio', 'encima', 'segun', 'como', 'ejemplo', 'él', 'nuestras', 'tras', 'unas', 'dijeron', 'seis', 'todos', 'otros', 'ellas', 'esta', 'claro', 'realizó', 'dejó', 'contra', 'vuestra', 'siempre', 'cualquier', 'agregó', 'gran', 'los', 'bastante', 'tuyos', 'una', 'lleva', 'tuyo', 'ellos', 'informó', 'haceis', 'empleais', 'habrá', 'tenía', 'cierta', 'son', 'por', 'muchas', 'qué', 'tenga', 'algún', 'todas', 'desde', 'bajo', 'entre', 'bien', 'mis', 'cuales', 'junto', 'nada', 'es', 'cuanta', 'segunda', 'aunque', 'llegó', 'varios', 'podrán', 'aseguró', 'ni', 'posible', 'llevar', 'debido', 'debajo', 'aquello', 'nosotras', 'cuánta', 'deprisa', 'mio', 'menos', 'quizás', 'últimas', 'vuestros', 'mediante', 'éstos', 'sabes', 'dias', 'había', 'sea', 'excepto', 'diferentes', 'cuál', 'eres', 'primeros', 'todavia', 'fue', 'propias', 'estaba', 'intentas', 'cierto', 'ahi', 'ambos', 'grandes', 'propio', 'lejos', 'podrias', 'ser', 'cuando', 'valor', 'ver', 'apenas', 'según', 'decir', 'ademas', 'tendrá', 'entonces', 'ésta', 'añadió', 'ultimo', 'existen', 'ésa', 'último', 'dieron', 'trabajamos', 'lado', 'incluso', 'podriais', 'quiénes', 'está', 'sería', 'vuestras', 'mientras', 'ninguno', 'mías', 'sino', 'tienen', 'para', 'más', 'creo', 'pues', 'manifestó', 'alguno', 'bueno', 'comentó', 'nuevo', 'ocho', 'breve', 'consideró', 'esas', 'pais', 'aún']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a eliminar las stop words\n",
    "\n",
    "stopwords_spacy = list(STOP_WORDS) #Checkar cuales son\n",
    "print(stopwords_spacy)\n",
    "len(stopwords_spacy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "370843ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meter?{'todo', 'seáis', 'estada', 'estoy', 'se', 'habrás', 'hubierais', 'hubiésemos', 'esta', 'le', 'habidos', 'estuviesen', 'has', 'suyas', 'ha', 'tú', 'tuviese', 'como', 'eres', 'tenga', 'habíais', 'hubiese', 'sentida', 'fuerais', 'es', 'seré', 'mía', 'tengan', 'me', 'nosotros', 'quienes', 'mi', 'otra', 'estarán', 'hubieseis', 'cuando', 'fueran', 'seamos', 'vosotras', 'o', 'tuya', 'eso', 'fuésemos', 'en', 'siente', 'tendrían', 'hayan', 'el', 'tendrás', 'fui', 'tiene', 'habiendo', 'del', 'habríais', 'estar', 'vuestras', 'nuestro', 'serías', 'estos', 'hayáis', 'seremos', 'tenemos', 'ellas', 'tuvierais', 'teníamos', 'mías', 'una', 'nada', 'habré', 'tu', 'sus', 'hube', 'no', 'estuvieron', 'y', 'estabas', 'fueses', 'sean', 'tendríamos', 'vuestra', 'esto', 'habrán', 'tengo', 'poco', 'tenidas', 'estadas', 'tenida', 'estuve', 'otro', 'míos', 'tuyas', 'al', 'otras', 'muchos', 'estarían', 'estéis', 'sí', 'estuvieras', 'te', 'tuvieran', 'estaremos', 'algo', 'nosotras', 'habéis', 'seríais', 'suyo', 'hubiéramos', 'tuviera', 'habrá', 'estaréis', 'de', 'había', 'tendríais', 'habías', 'hubiesen', 'otros', 'hubiste', 'ti', 'sentido', 'fuimos', 'tuyos', 'porque', 'tengáis', 'qué', 'fuese', 'la', 'su', 'nuestras', 'están', 'tuvimos', 'estuviésemos', 'éramos', 'muy', 'mucho', 'vosotros', 'algunas', 'he', 'sentidos', 'estuviese', 'ella', 'fuiste', 'estarás', 'fuéramos', 'uno', 'tenían', 'fueseis', 'ni', 'suyos', 'estaría', 'nuestros', 'estén', 'os', 'tengamos', 'estarías', 'les', 'estábamos', 'también', 'e', 'tendrán', 'está', 'estés', 'tuviésemos', 'sentidas', 'antes', 'mí', 'estemos', 'estaríais', 'soy', 'estuvisteis', 'quien', 'tuvieses', 'estáis', 'que', 'fueron', 'esas', 'hubimos', 'tuvieras', 'entre', 'tuviste', 'unos', 'esté', 'serán', 'habida', 'estaban', 'hayamos', 'fue', 'todos', 'estaríamos', 'serás', 'ellos', 'estado', 'tenías', 'estando', 'estaba', 'estuviéramos', 'vuestros', 'habrías', 'hemos', 'fuisteis', 'tenidos', 'desde', 'esa', 'habría', 'tenéis', 'estuvierais', 'tendré', 'tendrías', 'hayas', 'hubieron', 'sintiendo', 'con', 'habréis', 'habido', 'tendremos', 'estad', 'teniendo', 'vuestro', 'será', 'ya', 'fuera', 'durante', 'hay', 'hubieses', 'han', 'más', 'estuviera', 'estuvieses', 'habíamos', 'son', 'para', 'tenido', 'tuvieron', 'sois', 'esos', 'por', 'estamos', 'sin', 'ese', 'nos', 'tus', 'tuvieseis', 'cual', 'hubisteis', 'habríamos', 'habrían', 'tenía', 'suya', 'eran', 'contra', 'mis', 'habremos', 'estuviste', 'a', 'hubieras', 'estuvieran', 'hubo', 'sentid', 'sobre', 'seas', 'somos', 'algunos', 'pero', 'eras', 'erais', 'tuve', 'hubiera', 'sería', 'hubieran', 'tened', 'tuyo', 'fuesen', 'tendrá', 'tienen', 'seréis', 'mío', 'sea', 'hasta', 'teníais', 'ante', 'tendría', 'nuestra', 'tuviesen', 'habían', 'habidas', 'este', 'un', 'serían', 'donde', 'lo', 'era', 'fueras', 'haya', 'estados', 'seríamos', 'tienes', 'estará', 'estabais', 'estuvieseis', 'estaré', 'las', 'los', 'tuviéramos', 'estás', 'tuvo', 'tendréis', 'tengas', 'estuvo', 'estas', 'él', 'tanto', 'estuvimos', 'tuvisteis', 'yo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e74bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gato\n",
      "casa\n",
      ".\n",
      "granja\n",
      "nevera\n",
      ".\n",
      "frase\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.is_stop == False:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e795fb",
   "metadata": {},
   "source": [
    "# Clasificacion de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47011249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e53f86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar las librerías necesarias para leer los archivos de TASS\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de España\n",
    "with open(\"TASS2019_country_ES_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60cf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a json el diccionario\n",
    "json_data = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribir en un archivo el resultado en json\n",
    "with open(\"TASS2019_country_ES_train.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de datos en la fuente\n",
    "#Original en json\n",
    "fin = open(\"TASS2019_country_ES_train.json\", \"rt\")\n",
    "#Archivo resultante en json\n",
    "fout = open(\"TASS2019_country_ES_train-sintilde.json\", \"wt\")\n",
    "#Procesamiento de lìneas del archivo\n",
    "for line in fin:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "    fout.write(strtmp1)\n",
    "#cerrar archivos\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c76f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomar los datos del archivo creado en un dataframe\n",
    "train_df = pd.read_json('TASS2019_country_ES_train-sintilde.json')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337f394",
   "metadata": {},
   "source": [
    "#Función para eliminar las menciones a otros usuarios de twitter\n",
    "def filter_reply(content):\n",
    "    temp = content\n",
    "    while temp.find(\"@\") > -1:\n",
    "        print (temp)\n",
    "        temp = temp[:temp.find(\"@\")] + temp[(temp.find(\" \",temp.find(\"@\"))):]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193dd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp[:temp.find(\"@\")] + temp[(temp.find(\" \",temp.find(\"@\"))):]\n",
    "    \n",
    "print (temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b008b",
   "metadata": {},
   "source": [
    "#Quitar menciones del texto\n",
    "train_df['content'] = train_df['content'].apply(filter_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787aabd",
   "metadata": {},
   "source": [
    "## Test Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce35aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_final_final_resultado = pd.read_csv('final_final_resultado.csv')\n",
    "\n",
    "for line in final_final_final_resultado:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3b880ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768213567418036224</td>\n",
       "      <td>3429794128</td>\n",
       "      <td>@myendlesshazza a que puto mal escribo b me si...</td>\n",
       "      <td>2016-08-23 22:29:21+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768221670255493120</td>\n",
       "      <td>396616007</td>\n",
       "      <td>quiero mogollon a @albabenito99 pero sobretodo...</td>\n",
       "      <td>2016-08-23 23:01:33+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768221021300264960</td>\n",
       "      <td>2845050061</td>\n",
       "      <td>vale he visto la tia bebiendose su regla y me ...</td>\n",
       "      <td>2016-08-23 22:58:58+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768220253730009088</td>\n",
       "      <td>442100979</td>\n",
       "      <td>@yulian_poe @guillermoterry1 ah mucho mas por ...</td>\n",
       "      <td>2016-08-23 22:55:55+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768231229439311872</td>\n",
       "      <td>529648312</td>\n",
       "      <td>@toni_end seria mejor que dejasen de emitir es...</td>\n",
       "      <td>2016-08-23 23:39:32+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid        user  \\\n",
       "0  768213567418036224  3429794128   \n",
       "1  768221670255493120   396616007   \n",
       "2  768221021300264960  2845050061   \n",
       "3  768220253730009088   442100979   \n",
       "4  768231229439311872   529648312   \n",
       "\n",
       "                                             content  \\\n",
       "0  @myendlesshazza a que puto mal escribo b me si...   \n",
       "1  quiero mogollon a @albabenito99 pero sobretodo...   \n",
       "2  vale he visto la tia bebiendose su regla y me ...   \n",
       "3  @yulian_poe @guillermoterry1 ah mucho mas por ...   \n",
       "4  @toni_end seria mejor que dejasen de emitir es...   \n",
       "\n",
       "                        date lang sentiment  \n",
       "0  2016-08-23 22:29:21+00:00   es         0  \n",
       "1  2016-08-23 23:01:33+00:00   es         1  \n",
       "2  2016-08-23 22:58:58+00:00   es         0  \n",
       "3  2016-08-23 22:55:55+00:00   es         1  \n",
       "4  2016-08-23 23:39:32+00:00   es         0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quitar columnas sin clasificación de sentimiento \n",
    "indexNames = final_final_final_resultado[(final_final_final_resultado['sentiment'] == 'none') | (final_final_final_resultado['sentiment'] == 'neu')].index\n",
    "final_final_final_resultado.drop(indexNames , inplace=True)\n",
    "final_final_final_resultado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c62927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías de aprendizaje\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20390c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2854\n",
       "1    1896\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar frecuencias de cada categoría\n",
    "final_final_final_resultado['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f123234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid      0\n",
       "user         0\n",
       "content      0\n",
       "date         0\n",
       "lang         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificar si hay datos nulos\n",
    "final_final_final_resultado.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801e219b",
   "metadata": {},
   "source": [
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13823587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~¡¿'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string #Quita todos los simbolos\n",
    "puntua = string.punctuation + \"¡¿\"\n",
    "puntua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6de0d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para limpieza de datos\n",
    "def text_data_cleaning(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.lemma_ != \"-PRON-\":\n",
    "            temp = token.lemma_.strip()\n",
    "        else:\n",
    "            temp = token\n",
    "        tokens.append(temp)\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stopwords_spacy and token not in puntua:\n",
    "            clean_tokens.append(token)\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7faaeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola', 'Te', 'gustar', 'meetup']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_cleaning(\"¡Hola cómo estás!. ¿Te gusta el meetup?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7da3d",
   "metadata": {},
   "source": [
    "# Vectorization Feature Engineering (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf79c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librería de vectorización\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c18f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir la función de tokenizado y crear el clasificador lineal\n",
    "tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c319f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear los vectores de datos\n",
    "X = final_final_final_resultado['content']\n",
    "y = final_final_final_resultado['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f21f2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3800,), (950,), (3800,), (950,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear el vector de entrenamiento como una porción de los datos y dejar el resto para pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c9f140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un pipeline\n",
    "clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "389bf039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evitar que el formato se tome como unknown\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c509811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<function text_data_cleaning at 0x7fedfeb39670>)),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenar el clasificador\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16315ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el vectos de valores predichos a partir del clasificador\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0164c76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       578\n",
      "           1       0.84      0.78      0.81       372\n",
      "\n",
      "    accuracy                           0.86       950\n",
      "   macro avg       0.85      0.84      0.85       950\n",
      "weighted avg       0.86      0.86      0.85       950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ver la precisión obtenida\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67e41ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86% de 'efectividad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94849b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[522,  56],\n",
       "       [ 81, 291]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear la matriz de confusión\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863cc624",
   "metadata": {},
   "source": [
    "Me dan 82 falsos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir algunas frases de prueba\n",
    "clf.predict(['Eres una calamidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51263cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9622957",
   "metadata": {},
   "source": [
    "# Función-Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50a268f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b236b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 authentication chains\n",
    "\n",
    "consumer_key='Qbxaw0OrPeZSFljKEp6SHI19M'\n",
    "consumer_secret='kva4UfB6cK2Z6P70MGV8LAM0MMOu3SAHjuUl5t7bWxpegkCHGl'\n",
    "access_key='902474996-eLIpuPP1uqYZoTWtprZuiL2FmehUURAZHT8ZBReU'\n",
    "access_secret='CkVPZlMz5Lk4EMYDZzmNM2zJQHGE0ze6CA0auHqnYtEhU'\n",
    "\n",
    "# authorize twitter, initialize tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06cbd5",
   "metadata": {},
   "source": [
    "## Creo base de datos necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eef582",
   "metadata": {},
   "source": [
    "## Creando SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0defa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86950f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed3f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd5c0c6",
   "metadata": {},
   "source": [
    "### Dataframe Acierto Tweets\n",
    "\n",
    "El objetivo de este dataframe es guardar aquellos tweets que ha identificado bien como buenos tweets, para posteriormente, poder entrenar mi modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22232522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero que tenga las columnas: tweetid, user, content, date, lang, sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bffc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed47f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ceb9c28",
   "metadata": {},
   "source": [
    "### Dataframe Fallos Block\n",
    "\n",
    "El objetivo de este dataframe es guardar aquellos tweets que no ha identificado bien como malo sentimiento, para posteriormente, poder entrenar mi modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fba588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero que tenga las columnas: tweetid, user, content, date, lang, sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b4797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4608abc6",
   "metadata": {},
   "source": [
    "### Dataframe Listado de bullies \n",
    "\n",
    "El objetivo de este dataframe es guardar aquellos tweets que hacen daño a los usuarios, para posteriormente, poder tener un registro para poder denunciar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa155615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiero que tenga las columnas: tweetid, user, content, date, lang, sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f1794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32dc013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f391e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45979859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voy a bloquear a  javirando por el siguiente tweet: @xinxinricardo Vamooooo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-66d8710a4e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Voy a bloquear a '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'por el siguiente tweet:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mverif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'¿Deseas bloquear a este usuario?'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Estas seguro que quieres bloquear?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mverif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/clase/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             )\n\u001b[0;32m--> 848\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/clase/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "user = []\n",
    "\n",
    "mentions = api.mentions_timeline(tweet_mode= 'extented')\n",
    "    \n",
    "for tweet in mentions: # Entran los tweets\n",
    "    \n",
    "    valoracion = clf.predict([tweet.text]) \n",
    "    \n",
    "    if valoracion == 1: # Es positivo el tweet?\n",
    "        \n",
    "        print ('Es buena gente')\n",
    "        \n",
    "    elif valoracion == 0: # Es negativo el tweet?\n",
    "        \n",
    "        print('Voy a bloquear a ', tweet.user.screen_name, 'por el siguiente tweet:', tweet.text )\n",
    "               \n",
    "        verif = input ('¿Deseas bloquear a este usuario?') # Estas seguro que quieres bloquear?\n",
    "        \n",
    "        print (verif)\n",
    "        \n",
    "        if verif == 'Si': # Si\n",
    "            \n",
    "            api.create_block(tweet.user.screen_name)\n",
    "            \n",
    "            print('Bloqueado.')\n",
    "\n",
    "            \n",
    "        elif verif == 'No': # No\n",
    "            \n",
    "            print ('Perdón por las molestias. Tengo mucho que aprender.')\n",
    "        \n",
    "        \n",
    "\n",
    "    #print(tweet.created_at)\n",
    "    #print(tweet.text)\n",
    "    #print(tweet.source)\n",
    "    #print(tweet.user.name)\n",
    "        \n",
    "    #user.append(tweet.User)\n",
    "        \n",
    "#for i in tweet.user:\n",
    "        \n",
    "        #name = i.name\n",
    "        #screen_name = i.screen_name\n",
    "        #location = i.location if i.location else ''\n",
    "        #url = 'https://twitter.com/' + i.screen_name\n",
    "        #followers_count = i.followers_count\n",
    "        #verified = i.verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da95ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
