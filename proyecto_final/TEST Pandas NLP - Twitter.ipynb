{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15889d31",
   "metadata": {},
   "source": [
    "# Unificar XML en un mismo Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6811a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar las librerías necesarias para leer los archivos de TASS\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b95221",
   "metadata": {},
   "source": [
    "## Costa Rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de Costa Rica\n",
    "with open(\"train_modelo/TASS2019_country_CR_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ccd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a json el diccionario\n",
    "json_data = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe85c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribir en un archivo el resultado en json\n",
    "with open(\"train_modelo/TASS2019_country_CR_train.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de datos en la fuente\n",
    "#Original en json\n",
    "fin = open(\"train_modelo/TASS2019_country_CR_train.json\", \"rt\")\n",
    "#Archivo resultante en json\n",
    "fout = open(\"train_modelo/TASS2019_country_CR_train-sintilde.json\", \"wt\")\n",
    "#Procesamiento de lìneas del archivo\n",
    "for line in fin:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "    fout.write(strtmp1)\n",
    "#cerrar archivos\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc081367",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_json('Data.json', lines=True)\n",
    "\n",
    "you can try out other things like\n",
    "\n",
    "data= pd.read_json('Data.json', lines=True, orient='records')\n",
    "\n",
    "data= pd.read_json('Data.json', orient=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomar los datos del archivo creado en un dataframe\n",
    "train_df = pd.read_json('TASS2019_country_CR_train-sintilde.json')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9c1e8",
   "metadata": {},
   "source": [
    "## Uruguay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de Uruguay\n",
    "with open(\"train_modelo/TASS2019_country_UY_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097274a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a json el diccionario\n",
    "json_data = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribir en un archivo el resultado en json\n",
    "with open(\"train_modelo/TASS2019_country_UY_train.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de datos en la fuente\n",
    "#Original en json\n",
    "fin = open(\"train_modelo/TASS2019_country_UY_train.json\", \"rt\")\n",
    "#Archivo resultante en json\n",
    "fout = open(\"train_modelo/TASS2019_country_UY_train-sintilde.json\", \"wt\")\n",
    "#Procesamiento de lìneas del archivo\n",
    "for line in fin:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "    fout.write(strtmp1)\n",
    "#cerrar archivos\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomar los datos del archivo creado en un dataframe\n",
    "train_df = pd.read_json('train_modelo/TASS2019_country_UY_train-sintilde.json')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a848ed9",
   "metadata": {},
   "source": [
    "## Perú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89134243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de Perú\n",
    "with open(\"train_modelo/TASS2019_country_PE_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a json el diccionario\n",
    "json_data = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333eaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribir en un archivo el resultado en json\n",
    "with open(\"train_modelo/TASS2019_country_PE_train.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de datos en la fuente\n",
    "#Original en json\n",
    "fin = open(\"train_modelo/TASS2019_country_PE_train.json\", \"rt\")\n",
    "#Archivo resultante en json\n",
    "fout = open(\"train_modelo/TASS2019_country_PE_train-sintilde.json\", \"wt\")\n",
    "#Procesamiento de lìneas del archivo\n",
    "for line in fin:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "    fout.write(strtmp1)\n",
    "#cerrar archivos\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6386201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomar los datos del archivo creado en un dataframe\n",
    "train_df = pd.read_json('train_modelo/TASS2019_country_PE_train-sintilde.json')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266221df",
   "metadata": {},
   "source": [
    "## Mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de Mexico\n",
    "with open(\"train_modelo/TASS2019_country_MX_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir a json el diccionario\n",
    "json_data = json.dumps(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribir en un archivo el resultado en json\n",
    "with open(\"train_modelo/TASS2019_country_MX_train.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpieza de datos en la fuente\n",
    "#Original en json\n",
    "fin = open(\"train_modelo/TASS2019_country_MX_train.json\", \"rt\")\n",
    "#Archivo resultante en json\n",
    "fout = open(\"train_modelo/TASS2019_country_MX_train-sintilde.json\", \"wt\")\n",
    "#Procesamiento de lìneas del archivo\n",
    "for line in fin:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())\n",
    "    fout.write(strtmp1)\n",
    "#cerrar archivos\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomar los datos del archivo creado en un dataframe\n",
    "train_df = pd.read_json('train_modelo/TASS2019_country_MX_train-sintilde.json')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08027cb",
   "metadata": {},
   "source": [
    "# CSV Adjetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjetivos = pd.read_csv('adjetivos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9f7aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767817507897872384</td>\n",
       "      <td>71463624</td>\n",
       "      <td>grande</td>\n",
       "      <td>2016-08-22 20:15:33+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767817507897872385</td>\n",
       "      <td>71463624</td>\n",
       "      <td>gordo</td>\n",
       "      <td>2016-08-22 20:15:33+00:01</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767817507897872386</td>\n",
       "      <td>71463624</td>\n",
       "      <td>estrecho</td>\n",
       "      <td>2016-08-22 20:15:33+00:02</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767817507897872387</td>\n",
       "      <td>71463624</td>\n",
       "      <td>grotesco</td>\n",
       "      <td>2016-08-22 20:15:33+00:03</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767817507897872388</td>\n",
       "      <td>71463624</td>\n",
       "      <td>torpe</td>\n",
       "      <td>2016-08-22 20:15:33+00:04</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>767817507897872880</td>\n",
       "      <td>71463624</td>\n",
       "      <td>capullo</td>\n",
       "      <td>2016-08-22 20:15:33+00:496</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>767817507897872881</td>\n",
       "      <td>71463624</td>\n",
       "      <td>capulla</td>\n",
       "      <td>2016-08-22 20:15:33+00:497</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>767817507897872882</td>\n",
       "      <td>71463624</td>\n",
       "      <td>payaso</td>\n",
       "      <td>2016-08-22 20:15:33+00:498</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>767817507897872883</td>\n",
       "      <td>71463624</td>\n",
       "      <td>payasa</td>\n",
       "      <td>2016-08-22 20:15:33+00:499</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>767817507897872884</td>\n",
       "      <td>71463624</td>\n",
       "      <td>fraudulento</td>\n",
       "      <td>2016-08-22 20:15:33+00:500</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweetid      user      content                        date  \\\n",
       "0    767817507897872384  71463624       grande   2016-08-22 20:15:33+00:00   \n",
       "1    767817507897872385  71463624        gordo   2016-08-22 20:15:33+00:01   \n",
       "2    767817507897872386  71463624     estrecho   2016-08-22 20:15:33+00:02   \n",
       "3    767817507897872387  71463624     grotesco   2016-08-22 20:15:33+00:03   \n",
       "4    767817507897872388  71463624        torpe   2016-08-22 20:15:33+00:04   \n",
       "..                  ...       ...          ...                         ...   \n",
       "496  767817507897872880  71463624      capullo  2016-08-22 20:15:33+00:496   \n",
       "497  767817507897872881  71463624      capulla  2016-08-22 20:15:33+00:497   \n",
       "498  767817507897872882  71463624       payaso  2016-08-22 20:15:33+00:498   \n",
       "499  767817507897872883  71463624       payasa  2016-08-22 20:15:33+00:499   \n",
       "500  767817507897872884  71463624  fraudulento  2016-08-22 20:15:33+00:500   \n",
       "\n",
       "    lang  sentiment  \n",
       "0     es          1  \n",
       "1     es          0  \n",
       "2     es          0  \n",
       "3     es          0  \n",
       "4     es          0  \n",
       "..   ...        ...  \n",
       "496   es          0  \n",
       "497   es          0  \n",
       "498   es          0  \n",
       "499   es          0  \n",
       "500   es          0  \n",
       "\n",
       "[501 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937243ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de lìneas del archivo\n",
    "for line in adjetivos:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667d0c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767817507897872384</td>\n",
       "      <td>71463624</td>\n",
       "      <td>grande</td>\n",
       "      <td>2016-08-22 20:15:33+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767817507897872385</td>\n",
       "      <td>71463624</td>\n",
       "      <td>gordo</td>\n",
       "      <td>2016-08-22 20:15:33+00:01</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767817507897872386</td>\n",
       "      <td>71463624</td>\n",
       "      <td>estrecho</td>\n",
       "      <td>2016-08-22 20:15:33+00:02</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767817507897872387</td>\n",
       "      <td>71463624</td>\n",
       "      <td>grotesco</td>\n",
       "      <td>2016-08-22 20:15:33+00:03</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767817507897872388</td>\n",
       "      <td>71463624</td>\n",
       "      <td>torpe</td>\n",
       "      <td>2016-08-22 20:15:33+00:04</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid      user   content                       date lang  \\\n",
       "0  767817507897872384  71463624    grande  2016-08-22 20:15:33+00:00   es   \n",
       "1  767817507897872385  71463624     gordo  2016-08-22 20:15:33+00:01   es   \n",
       "2  767817507897872386  71463624  estrecho  2016-08-22 20:15:33+00:02   es   \n",
       "3  767817507897872387  71463624  grotesco  2016-08-22 20:15:33+00:03   es   \n",
       "4  767817507897872388  71463624     torpe  2016-08-22 20:15:33+00:04   es   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjetivos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583f44a",
   "metadata": {},
   "source": [
    "# CSV Adjetivos 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3289a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjetivos2 = pd.read_csv('adjetivos2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5742c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procesamiento de lìneas del archivo\n",
    "for line in adjetivos:\n",
    "\t#Reemplazar los caracteres unicode, no se dejaron tildes porque causan error\n",
    "    strtmp1 = line.replace('\\\\u00f1', 'ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e1', 'a')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00e9', 'e')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00ed', 'i')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00f3', 'o')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fa', 'u')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00bf', '¿')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00a1', '¡')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d1', 'Ñ')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c1', 'A')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00c9', 'E')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00cd', 'I')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00d3', 'O')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00da', 'U')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00fc', 'ü')\n",
    "    strtmp1 = strtmp1.replace('\\\\u00b0', '')\n",
    "    #Quitar el inicio y el fin del json para dejar solo los tweets\n",
    "    strtmp1 = strtmp1.replace('{\"tweets\": {\"tweet\": ', '')\n",
    "    strtmp1 = strtmp1.replace(']}}', ']')\n",
    "    #Quitar el diccionario que contiene la polaridad y dejarla solo con su valor de sentimiento\n",
    "    strtmp1 = strtmp1.replace('\"sentiment\": {\"polarity\": {\"value\": ', '\"sentiment\": ')\n",
    "    strtmp1 = strtmp1.replace('\"NONE\"}}', '\"NONE\"')\n",
    "    #Asignamos al sentimiento positivo el valor de 1\n",
    "    strtmp1 = strtmp1.replace('\"P\"}}', '1')\n",
    "    strtmp1 = strtmp1.replace('\"NEU\"}}', '\"NEU\"')\n",
    "    #Asignamos al sentimiento negativo el valor de 0\n",
    "    strtmp1 = strtmp1.replace('\"N\"}}', '0')\n",
    "    #eliminación de puntuaciones\n",
    "    strtmp1 = re.sub('[¡!#$).;¿?&°]', '', strtmp1.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78022909",
   "metadata": {},
   "source": [
    "# CSV España 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traer el archivo xml original xml y convertirlo en un diccionario, escogimos el de Mexico\n",
    "with open(\"train_modelo/TASS2019_country_MX_train.xml\") as xml_file: # Lo abro\n",
    "    data_dict = xmltodict.parse(xml_file.read()) # Lo paso a diccionario\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa1539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa38879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ee80d9c",
   "metadata": {},
   "source": [
    "# CSV CR 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7385441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04f9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e84f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c22cac2",
   "metadata": {},
   "source": [
    "# CSV Peru 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94283357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96722c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81493dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284682c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67644aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132720af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57f5f2e",
   "metadata": {},
   "source": [
    "# CSV completo final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b7ac1",
   "metadata": {},
   "source": [
    "## Unificar 4 Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3092d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultado = [espana, uruguay, peru,mex,adjetivos, adjetivos2]\n",
    "\n",
    "result = pd.concat(final_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0c24191",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultado = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccb7d9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6027, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_resultado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d47a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resultado = final_resultado.to_csv('final_final_resultado.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a3a1e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f287c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
